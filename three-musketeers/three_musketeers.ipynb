{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta notebook contiene bloques de código útiles para el juego The Three Musketeers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Juego original: https://www.onlinesologames.com/three-musketeers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from three_musketeers_env import ThreeMusketeersEnv\n",
    "from captain_pete import CaptainPete\n",
    "from play import play_multiple_games, plot_results, play_vs_other_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuracion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_games_value = 100           #Número de juegos a jugar\n",
    "grid_size_value = 5             #Tamaño del tablero\n",
    "\n",
    "max_depth_value=3               #Profundidad máxima de la búsqueda\n",
    "\n",
    "alignment_weight_value=10       #Peso de la alineación de las piezas\n",
    "trap_weight_value=20            #Peso de caer en las trampas\n",
    "moves_weight_value=10           #Peso de la cantidad de movimientos posibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No cambiar\n",
    "env = ThreeMusketeersEnv(grid_size_value, render_mode='rgb_array')\n",
    "self_player = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minimax vs Captain Pete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mini_max_agent import MiniMaxAgent\n",
    "\n",
    "agent1 = MiniMaxAgent(self_player,\n",
    "                      max_depth_value, \n",
    "                      alignment_weight_value, \n",
    "                      trap_weight_value, \n",
    "                      moves_weight_value)\n",
    "\n",
    "agent, pete_men = play_multiple_games(env, agent1, agent2=CaptainPete(2), num_games=num_games_value)\n",
    "plot_results(agent, pete_men)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ExpectiMax vs Captain Pete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from expecti_max_agent import ExpectiMaxAgent\n",
    "\n",
    "agent1 = ExpectiMaxAgent(self_player,\n",
    "                        max_depth_value, \n",
    "                        alignment_weight_value, \n",
    "                        trap_weight_value, \n",
    "                        moves_weight_value)\n",
    "\n",
    "agent, pete_men = play_multiple_games(env, agent1, agent2=CaptainPete(2), num_games=num_games_value)\n",
    "plot_results(agent, pete_men)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from three_musketeers_env import ThreeMusketeersEnv\n",
    "from mini_max_agent import MiniMaxAgent\n",
    "from expecti_max_agent import ExpectiMaxAgent\n",
    "from captain_pete import CaptainPete\n",
    "from play import play_multiple_games, plot_results\n",
    "\n",
    "def sweep_minimax():\n",
    "    wandb.init()\n",
    "    config = wandb.config\n",
    "\n",
    "    env = ThreeMusketeersEnv(grid_size=5, render_mode='rgb_array')\n",
    "    self_player = 1\n",
    "\n",
    "    agent1 = MiniMaxAgent(self_player,\n",
    "                          config.max_depth, \n",
    "                          config.alignment_weight, \n",
    "                          config.trap_weight, \n",
    "                          config.moves_weight)\n",
    "\n",
    "    agent_wins, pete_wins = play_multiple_games(env, agent1, agent2=CaptainPete(2), num_games=num_games_value)\n",
    "    \n",
    "    win_rate = agent_wins / num_games_value\n",
    "    wandb.log({\"win_rate\": win_rate, \"agent_wins\": agent_wins, \"pete_wins\": pete_wins})\n",
    "\n",
    "def sweep_expectimax():\n",
    "    wandb.init()\n",
    "    config = wandb.config\n",
    "\n",
    "    env = ThreeMusketeersEnv(grid_size=5, render_mode='rgb_array')\n",
    "    self_player = 1\n",
    "\n",
    "    agent1 = ExpectiMaxAgent(self_player,\n",
    "                             config.max_depth, \n",
    "                             config.alignment_weight, \n",
    "                             config.trap_weight, \n",
    "                             config.moves_weight)\n",
    "\n",
    "    agent_wins, pete_wins = play_multiple_games(env, agent1, agent2=CaptainPete(2), num_games=num_games_value)\n",
    "    \n",
    "    win_rate = agent_wins / num_games_value \n",
    "    wandb.log({\"win_rate\": win_rate, \"agent_wins\": agent_wins, \"pete_wins\": pete_wins})\n",
    "\n",
    "minimax_sweep_config = {\n",
    "    'name': 'minimax-sweep',\n",
    "    'method': 'bayes',\n",
    "    'metric': {\n",
    "        'name': 'win_rate',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'max_depth': {\n",
    "            'distribution': 'int_uniform',\n",
    "            'min': 2,\n",
    "            'max': 5\n",
    "        },\n",
    "        'alignment_weight': {\n",
    "            'distribution': 'uniform',\n",
    "            'min': 5,\n",
    "            'max': 20\n",
    "        },\n",
    "        'trap_weight': {\n",
    "            'distribution': 'uniform',\n",
    "            'min': 10,\n",
    "            'max': 30\n",
    "        },\n",
    "        'moves_weight': {\n",
    "            'distribution': 'uniform',\n",
    "            'min': 5,\n",
    "            'max': 15\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Sweep configuration for ExpectiMaxAgent\n",
    "expectimax_sweep_config = {\n",
    "    'name': 'expectimax-sweep',\n",
    "    'method': 'bayes',\n",
    "    'metric': {\n",
    "        'name': 'win_rate',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters': {\n",
    "        'max_depth': {\n",
    "            'distribution': 'int_uniform',\n",
    "            'min': 2,\n",
    "            'max': 5\n",
    "        },\n",
    "        'alignment_weight': {\n",
    "            'distribution': 'uniform',\n",
    "            'min': 5,\n",
    "            'max': 20\n",
    "        },\n",
    "        'trap_weight': {\n",
    "            'distribution': 'uniform',\n",
    "            'min': 10,\n",
    "            'max': 30\n",
    "        },\n",
    "        'moves_weight': {\n",
    "            'distribution': 'uniform',\n",
    "            'min': 5,\n",
    "            'max': 15\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Initialize the sweeps\n",
    "entity = \"mateogiraz27-ort\"\n",
    "project = \"three-musketeers\"\n",
    "#minimax_sweep_id = wandb.sweep(minimax_sweep_config, entity=entity, project=project)\n",
    "expectimax_sweep_id = wandb.sweep(expectimax_sweep_config, entity=entity, project=project)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the minimax sweep\n",
    "wandb.agent(\"txk212na\", function=sweep_minimax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the expectimax sweep\n",
    "wandb.agent(\"btf8pcci\", function=sweep_expectimax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Poetry)",
   "language": "python",
   "name": "poetry-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
